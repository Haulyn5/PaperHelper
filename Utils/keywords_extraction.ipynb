{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "# 设置查询参数\n",
    "params = {\n",
    "    'search': 'code',\n",
    "    'threshold': 0.0,  # 设置相似度阈值\n",
    "    'debug': 'True'   # 设置是否开启调试模式\n",
    "}\n",
    "\n",
    "# 构建查询字符串\n",
    "query_string = urllib.parse.urlencode(params)\n",
    "url = f\"http://127.0.0.1:40500/search?{query_string}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:40500/search?search=code&threshold=0.0&debug=True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 发送 GET 请求\n",
    "response = requests.get(url)\n",
    "print(url)\n",
    "# 检查响应状态并处理\n",
    "if response.status_code == 200:\n",
    "    papers = response.json()\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'abstract': 'The study explores the synergistic combination of Synthetic Aperture Radar\\n(SAR) and Visible-Near Infrared-Short Wave Infrared (VNIR-SWIR) imageries for\\nland use/land cover (LULC) classification. Image fusion, employing Bayesian\\nfusion, merges SAR texture bands with VNIR-SWIR imageries. The research aims to\\ninvestigate the impact of this fusion on LULC classification. Despite the\\npopularity of random forests for supervised classification, their limitations,\\nsuch as suboptimal performance with fewer features and accuracy stagnation, are\\naddressed. To overcome these issues, ensembles of random forests (RFE) are\\ncreated, introducing random rotations using the Forest-RC algorithm. Three\\nrotation approaches: principal component analysis (PCA), sparse random rotation\\n(SRP) matrix, and complete random rotation (CRP) matrix are employed.\\nSentinel-1 SAR data and Sentinel-2 VNIR-SWIR data from the IIT-Kanpur region\\nconstitute the training datasets, including SAR, SAR with texture, VNIR-SWIR,\\nVNIR-SWIR with texture, and fused VNIR-SWIR with texture. The study evaluates\\nclassifier efficacy, explores the impact of SAR and VNIR-SWIR fusion on\\nclassification, and significantly enhances the execution speed of Bayesian\\nfusion code. The SRP-based RFE outperforms other ensembles for the first two\\ndatasets, yielding average overall kappa values of 61.80% and 68.18%, while the\\nCRP-based RFE excels for the last three datasets with average overall kappa\\nvalues of 95.99%, 96.93%, and 96.30%. The fourth dataset achieves the highest\\noverall kappa of 96.93%. Furthermore, incorporating texture with SAR bands\\nresults in a maximum overall kappa increment of 10.00%, while adding texture to\\nVNIR-SWIR bands yields a maximum increment of approximately 3.45%.',\n",
       "  'arxiv_category': 'cs.CV, cs.AI, eess.IV',\n",
       "  'arxiv_id': '2312.10798',\n",
       "  'arxiv_upload_date': '2023-12-17T19:22:39',\n",
       "  'arxiv_url': 'https://arxiv.org/abs/2312.10798',\n",
       "  'authors': 'Shivam Pande',\n",
       "  'id': 30051,\n",
       "  'publication_date': None,\n",
       "  'publication_name': None,\n",
       "  'publication_url': None,\n",
       "  'title': 'Land use/land cover classification of fused Sentinel-1 and Sentinel-2   imageries using ensembles of Random Forests'},\n",
       " {'abstract': 'Symbolic music datasets are important for music information retrieval and\\nmusical analysis. However, there is a lack of large-scale symbolic datasets for\\nclassical piano music. In this article, we create a GiantMIDI-Piano (GP)\\ndataset containing 38,700,838 transcribed notes and 10,855 unique solo piano\\nworks composed by 2,786 composers. We extract the names of music works and the\\nnames of composers from the International Music Score Library Project (IMSLP).\\nWe search and download their corresponding audio recordings from the internet.\\nWe further create a curated subset containing 7,236 works composed by 1,787\\ncomposers by constraining the titles of downloaded audio recordings containing\\nthe surnames of composers. We apply a convolutional neural network to detect\\nsolo piano works. Then, we transcribe those solo piano recordings into Musical\\nInstrument Digital Interface (MIDI) files using a high-resolution piano\\ntranscription system. Each transcribed MIDI file contains the onset, offset,\\npitch, and velocity attributes of piano notes and pedals. GiantMIDI-Piano\\nincludes 90% live performance MIDI files and 10\\\\% sequence input MIDI files. We\\nanalyse the statistics of GiantMIDI-Piano and show pitch class, interval,\\ntrichord, and tetrachord frequencies of six composers from different eras to\\nshow that GiantMIDI-Piano can be used for musical analysis. We evaluate the\\nquality of GiantMIDI-Piano in terms of solo piano detection F1 scores, metadata\\naccuracy, and transcription error rates. We release the source code for\\nacquiring the GiantMIDI-Piano dataset at\\nhttps://github.com/bytedance/GiantMIDI-Piano',\n",
       "  'arxiv_category': 'cs.IR, cs.SD, eess.AS',\n",
       "  'arxiv_id': '2010.07061',\n",
       "  'arxiv_upload_date': '2020-10-11T01:23:43',\n",
       "  'arxiv_url': 'https://arxiv.org/abs/2010.07061',\n",
       "  'authors': 'Qiuqiang Kong, Bochen Li, Jitong Chen, Yuxuan Wang',\n",
       "  'id': 6752,\n",
       "  'publication_date': None,\n",
       "  'publication_name': None,\n",
       "  'publication_url': None,\n",
       "  'title': 'GiantMIDI-Piano: A large-scale MIDI dataset for classical piano music'},\n",
       " {'abstract': \"Deep neural networks (DNNs) have advanced many machine learning tasks, but\\ntheir performance is often harmed by noisy labels in real-world data.\\nAddressing this, we introduce CoLafier, a novel approach that uses Local\\nIntrinsic Dimensionality (LID) for learning with noisy labels. CoLafier\\nconsists of two subnets: LID-dis and LID-gen. LID-dis is a specialized\\nclassifier. Trained with our uniquely crafted scheme, LID-dis consumes both a\\nsample's features and its label to predict the label - which allows it to\\nproduce an enhanced internal representation. We observe that LID scores\\ncomputed from this representation effectively distinguish between correct and\\nincorrect labels across various noise scenarios. In contrast to LID-dis,\\nLID-gen, functioning as a regular classifier, operates solely on the sample's\\nfeatures. During training, CoLafier utilizes two augmented views per instance\\nto feed both subnets. CoLafier considers the LID scores from the two views as\\nproduced by LID-dis to assign weights in an adapted loss function for both\\nsubnets. Concurrently, LID-gen, serving as classifier, suggests pseudo-labels.\\nLID-dis then processes these pseudo-labels along with two views to derive LID\\nscores. Finally, these LID scores along with the differences in predictions\\nfrom the two subnets guide the label update decisions. This dual-view and\\ndual-subnet approach enhances the overall reliability of the framework. Upon\\ncompletion of the training, we deploy the LID-gen subnet of CoLafier as the\\nfinal classification model. CoLafier demonstrates improved prediction accuracy,\\nsurpassing existing methods, particularly under severe label noise. For more\\ndetails, see the code at https://github.com/zdy93/CoLafier.\",\n",
       "  'arxiv_category': 'cs.LG, cs.AI',\n",
       "  'arxiv_id': '2401.05458',\n",
       "  'arxiv_upload_date': '2024-01-10T08:10:59',\n",
       "  'arxiv_url': 'https://arxiv.org/abs/2401.05458',\n",
       "  'authors': 'Dongyu Zhang, Ruofan Hu, Elke Rundensteiner',\n",
       "  'id': 35812,\n",
       "  'publication_date': None,\n",
       "  'publication_name': None,\n",
       "  'publication_url': None,\n",
       "  'title': 'CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic   Dimensionality Guidance'},\n",
       " {'abstract': 'Context: Comprehensive studies of Wolf-Rayet stars were performed in the past\\nfor the Galactic and the LMC population. The results revealed significant\\ndifferences, but also unexpected similarities between the WR populations of\\nthese different galaxies. Analyzing the WR stars in M31 will extend our\\nunderstanding of these objects in different galactic environments. Aims: The\\npresent study aims at the late-type WN stars in M31. The stellar and wind\\nparameters will tell about the formation of WR stars in other galaxies with\\ndifferent metallicity and star formation histories. The obtained parameters\\nwill provide constraints to the evolution of massive stars in the environment\\nof M31. Methods: We used the latest version of the Potsdam Wolf-Rayet model\\natmosphere code to analyze the stars via fitting optical spectra and\\nphotometric data. To account for the relatively low temperatures of the late\\nWN10 and WN11 subtypes, our WN models have been extended into this temperature\\nregime. Results: Stellar and atmospheric parameters are derived for all known\\nlate-type WN stars in M31 with available spectra. All of these stars still have\\nhydrogen in their outer envelopes, some of them up to 50% by mass. The stars\\nare located on the cool side of the zero age main sequence in the\\nHertzsprung-Russell diagram, while their luminosities range from $10^5$ to\\n$10^6$ Lsun. It is remarkable that no star exceeds $10^6$ Lsun. Conclusions: If\\nformed via single-star evolution, the late-type WN stars in M31 stem from an\\ninitial mass range between 20 and 60 Msun. From the very late-type WN9-11\\nstars, only one star is located in the S Doradus instability strip. We do not\\nfind any late-type WN stars with the high luminosities known in the Milky Way.',\n",
       "  'arxiv_category': 'astro-ph.SR, astro-ph.GA',\n",
       "  'arxiv_id': '1402.2282',\n",
       "  'arxiv_upload_date': '2014-02-10T21:00:21',\n",
       "  'arxiv_url': 'https://arxiv.org/abs/1402.2282',\n",
       "  'authors': 'Andreas Sander, Helge Todt, Rainer Hainich, Wolf-Rainer Hamann',\n",
       "  'id': 27318,\n",
       "  'publication_date': None,\n",
       "  'publication_name': None,\n",
       "  'publication_url': None,\n",
       "  'title': 'The Wolf-Rayet stars in M31: I. Analysis of the late-type WN stars'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "example = [\n",
    "    {\n",
    "        \"query\":\"deep learning for code area, like coding, program, software, etc.\",\n",
    "        \"input\":\"\"\"http://127.0.0.1:40500/search?search=code&threshold=0.1&debug=True\n",
    "[{'abstract': 'We present a novel clustering algorithm, visClust, that is based on lower\\ndimensional data representations and visual interpretation. Thereto, we design\\na transformation that allows the data to be represented by a binary integer\\narray enabling the use of image processing methods to select a partition.\\nQualitative and quantitative analyses measured in accuracy and an adjusted\\nRand-Index show that the algorithm performs well while requiring low runtime\\nand RAM. We compare the results to 6 state-of-the-art algorithms with available\\ncode, confirming the quality of visClust by superior performance in most\\nexperiments. Moreover, the algorithm asks for just one obligatory input\\nparameter while allowing optimization via optional parameters. The code is made\\navailable on GitHub and straightforward to use.',\n",
    "  'arxiv_category': 'cs.CV',\n",
    "  'arxiv_id': '2211.03894',\n",
    "  'arxiv_upload_date': '2022-11-07T22:56:23',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2211.03894',\n",
    "  'authors': 'Anna Breger, Clemens Karner, Martin Ehler',\n",
    "  'id': 25711,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'visClust: A visual clustering algorithm based on orthogonal projections'},\n",
    " {'abstract': \"Software vulnerabilities are now reported at an unprecedented speed due to\\nthe recent development of automated vulnerability hunting tools. However,\\nfixing vulnerabilities still mainly depends on programmers' manual efforts.\\nDevelopers need to deeply understand the vulnerability and try to affect the\\nsystem's functions as little as possible.\\n  In this paper, with the advancement of Neural Machine Translation (NMT)\\ntechniques, we provide a novel approach called SeqTrans to exploit historical\\nvulnerability fixes to provide suggestions and automatically fix the source\\ncode. To capture the contextual information around the vulnerable code, we\\npropose to leverage data flow dependencies to construct code sequences and fed\\nthem into the state-of-the-art transformer model. The fine-tuning strategy has\\nbeen introduced to overcome the small sample size problem. We evaluate SeqTrans\\non a dataset containing 1,282 commits that fix 624 vulnerabilities in 205 Java\\nprojects. Results show that the accuracy of SeqTrans outperforms the latest\\ntechniques and achieves 23.3% in statement-level fix and 25.3% in CVE-level\\nfix. In the meantime, we look deep inside the result and observe that NMT model\\nperforms very well in certain kinds of vulnerabilities like CWE-287 (Improper\\nAuthentication) and CWE-863 (Incorrect Authorization).\",\n",
    "  'arxiv_category': 'cs.CR, cs.SE',\n",
    "  'arxiv_id': '2010.10805',\n",
    "  'arxiv_upload_date': '2020-10-21T07:49:08',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2010.10805',\n",
    "  'authors': 'Jianlei Chi, Yu Qu, Ting Liu, Qinghua Zheng, Heng Yin',\n",
    "  'id': 17090,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'SeqTrans: Automatic Vulnerability Fix via Sequence to Sequence Learning'},\n",
    " {'abstract': \"While language models are powerful and versatile, they often fail to address\\nhighly complex problems. This is because solving complex problems requires\\ndeliberate thinking, which has been only minimally guided during training. In\\nthis paper, we propose a new method called Cumulative Reasoning (CR), which\\nemploys language models in a cumulative and iterative manner to emulate human\\nthought processes. By decomposing tasks into smaller components, CR streamlines\\nthe problem-solving process, rendering it both more manageable and effective.\\nFor logical inference tasks, CR consistently outperforms existing methods with\\nan improvement up to 9.3%, and achieves an accuracy of 98.04% on the curated\\nFOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy\\nof 98%, which signifies a substantial enhancement of 24% over the previous\\nstate-of-the-art method. Finally, on the MATH dataset, we establish new\\nstate-of-the-art results with 58.0% overall accuracy, surpassing the previous\\nbest approach by a margin of 4.2%, and achieving 43% relative improvement on\\nthe hardest level 5 problems (22.4% to 32.1%). Additionally, we expand the\\nconcept of Cumulative Reasoning to incorporate a Python code environment,\\ndeliberately omitting external aids such as retrieval and web browsing and\\nfocusing solely on the LLM's intrinsic reasoning capabilities within a Python\\ncode environment. Our experiments in this setting yielded impressive results,\\nwith an overall accuracy of 72.2% on the MATH dataset, significantly\\noutperforming the PAL method with 38.8% relative improvement. Code is available\\nat https://github.com/iiis-ai/cumulative-reasoning.\",\n",
    "  'arxiv_category': 'cs.AI',\n",
    "  'arxiv_id': '2308.04371',\n",
    "  'arxiv_upload_date': '2023-08-08T16:18:20',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2308.04371',\n",
    "  'authors': 'Yifan Zhang, Jingqin Yang, Yang Yuan, Andrew Chi-Chih Yao',\n",
    "  'id': 25502,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'Cumulative Reasoning with Large Language Models'},\n",
    " {'abstract': 'Neural Code Completion Tools (NCCTs) have reshaped the field of software\\ndevelopment, which accurately suggest contextually-relevant code snippets\\nbenefiting from language modeling techniques. However, language models may emit\\nthe training data verbatim during inference with appropriate prompts. This\\nmemorization property raises privacy concerns of commercial NCCTs about the\\nhard-coded credential leakage, leading to unauthorized access to systems.\\nTherefore, to answer whether NCCTs will inadvertently emit the hard-coded\\ncredential, we propose an evaluation tool called Hard-coded Credential Revealer\\n(HCR). HCR effectively constructs test prompts from GitHub code files with\\ncredentials to trigger memorization phenomenon of commercial NCCTs. Then, HCR\\nextracts credentials with pre-defined format from the responses by four\\ndesigned filters. We apply HCR to evaluate two representative commercial NCCTs:\\nGitHub Copilot and Amazon CodeWhisperer and successfully extracted 2,702\\nhard-coded credentials from Copilot and 129 secrets from CodeWhisper under the\\nblack-box setting, among which at least 3.6% and 5.4% secrets are real strings\\nfrom GitHub repositories. Moreover, two operational credentials were\\nidentified. The experimental results raise the severe privacy concern of the\\npotential leakage of hard-coded credentials in the training data of commercial\\nNCCTs.',\n",
    "  'arxiv_category': 'cs.CR',\n",
    "  'arxiv_id': '2309.07639',\n",
    "  'arxiv_upload_date': '2023-09-14T12:05:02',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2309.07639',\n",
    "  'authors': 'Yizhan Huang, Yichen Li, Weibin Wu, Jianping Zhang, Michael R. Lyu',\n",
    "  'id': 4587,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'Do Not Give Away My Secrets: Uncovering the Privacy Issue of Neural Code   Completion Tools'}]\"\"\",\n",
    "  \"output\": \"1\"},\n",
    "  {\n",
    "      \"query\":\"deep learning for code area, like coding, program, software, etc.\",\n",
    "      \"input\":\"\"\"http://127.0.0.1:40500/search?search=code&threshold=0.0&debug=True\n",
    "[{'abstract': 'The study explores the synergistic combination of Synthetic Aperture Radar\\n(SAR) and Visible-Near Infrared-Short Wave Infrared (VNIR-SWIR) imageries for\\nland use/land cover (LULC) classification. Image fusion, employing Bayesian\\nfusion, merges SAR texture bands with VNIR-SWIR imageries. The research aims to\\ninvestigate the impact of this fusion on LULC classification. Despite the\\npopularity of random forests for supervised classification, their limitations,\\nsuch as suboptimal performance with fewer features and accuracy stagnation, are\\naddressed. To overcome these issues, ensembles of random forests (RFE) are\\ncreated, introducing random rotations using the Forest-RC algorithm. Three\\nrotation approaches: principal component analysis (PCA), sparse random rotation\\n(SRP) matrix, and complete random rotation (CRP) matrix are employed.\\nSentinel-1 SAR data and Sentinel-2 VNIR-SWIR data from the IIT-Kanpur region\\nconstitute the training datasets, including SAR, SAR with texture, VNIR-SWIR,\\nVNIR-SWIR with texture, and fused VNIR-SWIR with texture. The study evaluates\\nclassifier efficacy, explores the impact of SAR and VNIR-SWIR fusion on\\nclassification, and significantly enhances the execution speed of Bayesian\\nfusion code. The SRP-based RFE outperforms other ensembles for the first two\\ndatasets, yielding average overall kappa values of 61.80% and 68.18%, while the\\nCRP-based RFE excels for the last three datasets with average overall kappa\\nvalues of 95.99%, 96.93%, and 96.30%. The fourth dataset achieves the highest\\noverall kappa of 96.93%. Furthermore, incorporating texture with SAR bands\\nresults in a maximum overall kappa increment of 10.00%, while adding texture to\\nVNIR-SWIR bands yields a maximum increment of approximately 3.45%.',\n",
    "  'arxiv_category': 'cs.CV, cs.AI, eess.IV',\n",
    "  'arxiv_id': '2312.10798',\n",
    "  'arxiv_upload_date': '2023-12-17T19:22:39',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2312.10798',\n",
    "  'authors': 'Shivam Pande',\n",
    "  'id': 30051,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'Land use/land cover classification of fused Sentinel-1 and Sentinel-2   imageries using ensembles of Random Forests'},\n",
    " {'abstract': 'Symbolic music datasets are important for music information retrieval and\\nmusical analysis. However, there is a lack of large-scale symbolic datasets for\\nclassical piano music. In this article, we create a GiantMIDI-Piano (GP)\\ndataset containing 38,700,838 transcribed notes and 10,855 unique solo piano\\nworks composed by 2,786 composers. We extract the names of music works and the\\nnames of composers from the International Music Score Library Project (IMSLP).\\nWe search and download their corresponding audio recordings from the internet.\\nWe further create a curated subset containing 7,236 works composed by 1,787\\ncomposers by constraining the titles of downloaded audio recordings containing\\nthe surnames of composers. We apply a convolutional neural network to detect\\nsolo piano works. Then, we transcribe those solo piano recordings into Musical\\nInstrument Digital Interface (MIDI) files using a high-resolution piano\\ntranscription system. Each transcribed MIDI file contains the onset, offset,\\npitch, and velocity attributes of piano notes and pedals. GiantMIDI-Piano\\nincludes 90% live performance MIDI files and 10\\\\% sequence input MIDI files. We\\nanalyse the statistics of GiantMIDI-Piano and show pitch class, interval,\\ntrichord, and tetrachord frequencies of six composers from different eras to\\nshow that GiantMIDI-Piano can be used for musical analysis. We evaluate the\\nquality of GiantMIDI-Piano in terms of solo piano detection F1 scores, metadata\\naccuracy, and transcription error rates. We release the source code for\\nacquiring the GiantMIDI-Piano dataset at\\nhttps://github.com/bytedance/GiantMIDI-Piano',\n",
    "  'arxiv_category': 'cs.IR, cs.SD, eess.AS',\n",
    "  'arxiv_id': '2010.07061',\n",
    "  'arxiv_upload_date': '2020-10-11T01:23:43',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2010.07061',\n",
    "  'authors': 'Qiuqiang Kong, Bochen Li, Jitong Chen, Yuxuan Wang',\n",
    "  'id': 6752,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'GiantMIDI-Piano: A large-scale MIDI dataset for classical piano music'},\n",
    " {'abstract': \"Deep neural networks (DNNs) have advanced many machine learning tasks, but\\ntheir performance is often harmed by noisy labels in real-world data.\\nAddressing this, we introduce CoLafier, a novel approach that uses Local\\nIntrinsic Dimensionality (LID) for learning with noisy labels. CoLafier\\nconsists of two subnets: LID-dis and LID-gen. LID-dis is a specialized\\nclassifier. Trained with our uniquely crafted scheme, LID-dis consumes both a\\nsample's features and its label to predict the label - which allows it to\\nproduce an enhanced internal representation. We observe that LID scores\\ncomputed from this representation effectively distinguish between correct and\\nincorrect labels across various noise scenarios. In contrast to LID-dis,\\nLID-gen, functioning as a regular classifier, operates solely on the sample's\\nfeatures. During training, CoLafier utilizes two augmented views per instance\\nto feed both subnets. CoLafier considers the LID scores from the two views as\\nproduced by LID-dis to assign weights in an adapted loss function for both\\nsubnets. Concurrently, LID-gen, serving as classifier, suggests pseudo-labels.\\nLID-dis then processes these pseudo-labels along with two views to derive LID\\nscores. Finally, these LID scores along with the differences in predictions\\nfrom the two subnets guide the label update decisions. This dual-view and\\ndual-subnet approach enhances the overall reliability of the framework. Upon\\ncompletion of the training, we deploy the LID-gen subnet of CoLafier as the\\nfinal classification model. CoLafier demonstrates improved prediction accuracy,\\nsurpassing existing methods, particularly under severe label noise. For more\\ndetails, see the code at https://github.com/zdy93/CoLafier.\",\n",
    "  'arxiv_category': 'cs.LG, cs.AI',\n",
    "  'arxiv_id': '2401.05458',\n",
    "  'arxiv_upload_date': '2024-01-10T08:10:59',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/2401.05458',\n",
    "  'authors': 'Dongyu Zhang, Ruofan Hu, Elke Rundensteiner',\n",
    "  'id': 35812,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic   Dimensionality Guidance'},\n",
    " {'abstract': 'Context: Comprehensive studies of Wolf-Rayet stars were performed in the past\\nfor the Galactic and the LMC population. The results revealed significant\\ndifferences, but also unexpected similarities between the WR populations of\\nthese different galaxies. Analyzing the WR stars in M31 will extend our\\nunderstanding of these objects in different galactic environments. Aims: The\\npresent study aims at the late-type WN stars in M31. The stellar and wind\\nparameters will tell about the formation of WR stars in other galaxies with\\ndifferent metallicity and star formation histories. The obtained parameters\\nwill provide constraints to the evolution of massive stars in the environment\\nof M31. Methods: We used the latest version of the Potsdam Wolf-Rayet model\\natmosphere code to analyze the stars via fitting optical spectra and\\nphotometric data. To account for the relatively low temperatures of the late\\nWN10 and WN11 subtypes, our WN models have been extended into this temperature\\nregime. Results: Stellar and atmospheric parameters are derived for all known\\nlate-type WN stars in M31 with available spectra. All of these stars still have\\nhydrogen in their outer envelopes, some of them up to 50% by mass. The stars\\nare located on the cool side of the zero age main sequence in the\\nHertzsprung-Russell diagram, while their luminosities range from $10^5$ to\\n$10^6$ Lsun. It is remarkable that no star exceeds $10^6$ Lsun. Conclusions: If\\nformed via single-star evolution, the late-type WN stars in M31 stem from an\\ninitial mass range between 20 and 60 Msun. From the very late-type WN9-11\\nstars, only one star is located in the S Doradus instability strip. We do not\\nfind any late-type WN stars with the high luminosities known in the Milky Way.',\n",
    "  'arxiv_category': 'astro-ph.SR, astro-ph.GA',\n",
    "  'arxiv_id': '1402.2282',\n",
    "  'arxiv_upload_date': '2014-02-10T21:00:21',\n",
    "  'arxiv_url': 'https://arxiv.org/abs/1402.2282',\n",
    "  'authors': 'Andreas Sander, Helge Todt, Rainer Hainich, Wolf-Rainer Hamann',\n",
    "  'id': 27318,\n",
    "  'publication_date': None,\n",
    "  'publication_name': None,\n",
    "  'publication_url': None,\n",
    "  'title': 'The Wolf-Rayet stars in M31: I. Analysis of the late-type WN stars'}]\"\"\",\n",
    "  \"output\":\"0\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{query} {input}\"),\n",
    "        (\"ai\",\"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = example,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. You will get an input and a list of papers and you need to tell me if they are relevant to my query. Only return 1 if the paper is relevant, otherwise return 0.\"),\n",
    "        #few_shot_prompt,\n",
    "        (\"human\", \"{input} {papers}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"all_proxy\"]=\"socks5://127.0.0.1:7891/\"\n",
    "os.environ[\"http_proxy\"]=\"socks5://127.0.0.1:7891/\"\n",
    "os.environ[\"https_proxy\"]=\"socks5://127.0.0.1:7891/\"\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\")\n",
    "chain = final_prompt | model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"input\":\"Deep learning for code area, like coding, programing, etc. It show be about deep learning\",\n",
    "    \"papers\":papers[9:],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'abstract': \"Memory isolation is critical for system reliability, security, and safety.\\nUnfortunately, read disturbance can break memory isolation in modern DRAM\\nchips. For example, RowHammer is a well-studied read-disturb phenomenon where\\nrepeatedly opening and closing (i.e., hammering) a DRAM row many times causes\\nbitflips in physically nearby rows.\\n  This paper experimentally demonstrates and analyzes another widespread\\nread-disturb phenomenon, RowPress, in real DDR4 DRAM chips. RowPress breaks\\nmemory isolation by keeping a DRAM row open for a long period of time, which\\ndisturbs physically nearby rows enough to cause bitflips. We show that RowPress\\namplifies DRAM's vulnerability to read-disturb attacks by significantly\\nreducing the number of row activations needed to induce a bitflip by one to two\\norders of magnitude under realistic conditions. In extreme cases, RowPress\\ninduces bitflips in a DRAM row when an adjacent row is activated only once. Our\\ndetailed characterization of 164 real DDR4 DRAM chips shows that RowPress 1)\\naffects chips from all three major DRAM manufacturers, 2) gets worse as DRAM\\ntechnology scales down to smaller node sizes, and 3) affects a different set of\\nDRAM cells from RowHammer and behaves differently from RowHammer as temperature\\nand access pattern changes.\\n  We demonstrate in a real DDR4-based system with RowHammer protection that 1)\\na user-level program induces bitflips by leveraging RowPress while conventional\\nRowHammer cannot do so, and 2) a memory controller that adaptively keeps the\\nDRAM row open for a longer period of time based on access pattern can\\nfacilitate RowPress-based attacks. To prevent bitflips due to RowPress, we\\ndescribe and evaluate a new methodology that adapts existing RowHammer\\nmitigation techniques to also mitigate RowPress with low additional performance\\noverhead. We open source all our code and data to facilitate future research on\\nRowPress.\",\n",
       "  'arxiv_category': 'cs.CR, cs.AR',\n",
       "  'arxiv_id': '2306.17061',\n",
       "  'arxiv_upload_date': '2023-06-29T16:09:56',\n",
       "  'arxiv_url': 'https://arxiv.org/abs/2306.17061',\n",
       "  'authors': 'Haocong Luo, Ataberk Olgun, A. Giray Yağlıkçı, Yahya Can Tuğrul, Steve Rhyner, Meryem Banu Cavlak, Joël Lindegger, Mohammad Sadrosadati, Onur Mutlu',\n",
       "  'id': 35500,\n",
       "  'publication_date': None,\n",
       "  'publication_name': None,\n",
       "  'publication_url': None,\n",
       "  'title': 'RowPress: Amplifying Read Disturbance in Modern DRAM Chips'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_search(search, threshold=0.0, debug=True):\n",
    "    # 设置查询参数\n",
    "    params = {\n",
    "        'search': search,\n",
    "        'threshold': threshold,  # 设置相似度阈值\n",
    "        'debug': debug   # 设置是否开启调试模式\n",
    "    }\n",
    "\n",
    "    # 构建查询字符串\n",
    "    query_string = urllib.parse.urlencode(params)\n",
    "    url = f\"http://127.0.0.1:40500/search?{query_string}\"\n",
    "\n",
    "    # 发送 GET 请求\n",
    "    response = requests.get(url)\n",
    "    # 检查响应状态并处理\n",
    "    if response.status_code == 200:\n",
    "        papers = response.json()\n",
    "        return papers\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "1\n",
      "threshold - 0.05\n",
      "0.05\n",
      "0\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "flag = 1\n",
    "query = \"Deep learning for code area, like coding, programing, etc. It should be about deep learning\"\n",
    "search = \"code\"\n",
    "threshold = 0.1\n",
    "last_response = None\n",
    "last_threshold = None\n",
    "while flag:\n",
    "    print(threshold)\n",
    "    papers = paper_search(search, threshold, debug = True)\n",
    "    response = chain.invoke({\n",
    "        \"input\":query,\n",
    "        \"papers\":papers[9:],\n",
    "    })\n",
    "    print(response)\n",
    "    if response not in [0,1]:\n",
    "        raise Exception(\"invalid respnse\")\n",
    "    \n",
    "    if papers == [] and last_response == None:\n",
    "        raise Exception(\"no papers found\")\n",
    "    elif papers == [] and last_response != None:\n",
    "        results = paper_search(search, last_threshold, debug = False)\n",
    "\n",
    "    if last_response is not None and response != last_response:\n",
    "        print(\"over\")\n",
    "        results = paper_search(search, threshold, debug = False)\n",
    "        break\n",
    "    last_threshold = threshold\n",
    "    if response == 0:\n",
    "        print(\"threshold + 0.05\")\n",
    "        threshold += 0.05\n",
    "    elif response == 1:\n",
    "        print(\"threshold - 0.05\")\n",
    "        threshold -= 0.05\n",
    "    last_response = response\n",
    "    if threshold < 0:\n",
    "        threshold = 0\n",
    "        results = paper_search(search, threshold, debug = False)\n",
    "        break\n",
    "    if threshold > 1:\n",
    "        raise Exception(\"threshold > 1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Large Language Models (LLMs) have shown remarkable capabilities in processing\\nboth natural and programming languages, which have enabled various applications\\nin software engineering, such as requirement engineering, code generation, and\\nsoftware testing. However, existing code generation benchmarks do not\\nnecessarily assess the code understanding performance of LLMs, especially for\\nthe subtle inconsistencies that may arise between code and its semantics\\ndescribed in natural language.\\n  In this paper, we propose a novel method to systematically assess the code\\nunderstanding performance of LLMs, particularly focusing on subtle differences\\nbetween code and its descriptions, by introducing code mutations to existing\\ncode generation datasets. Code mutations are small changes that alter the\\nsemantics of the original code, creating a mismatch with the natural language\\ndescription. We apply different types of code mutations, such as operator\\nreplacement and statement deletion, to generate inconsistent code-description\\npairs. We then use these pairs to test the ability of LLMs to correctly detect\\nthe inconsistencies.\\n  We propose a new LLM testing method, called Mutation-based Consistency\\nTesting (MCT), and conduct a case study on the two popular LLMs, GPT-3.5 and\\nGPT-4, using the state-of-the-art code generation benchmark, HumanEval-X, which\\nconsists of six programming languages (Python, C++, Java, Go, JavaScript, and\\nRust). We compare the performance of the LLMs across different types of code\\nmutations and programming languages and analyze the results. We find that the\\nLLMs show significant variation in their code understanding performance and\\nthat they have different strengths and weaknesses depending on the mutation\\ntype and language.',\n",
       " 'arxiv_category': 'cs.SE, cs.AI',\n",
       " 'arxiv_id': '2401.05940',\n",
       " 'arxiv_upload_date': '2024-01-11T14:27:43',\n",
       " 'arxiv_url': 'https://arxiv.org/abs/2401.05940',\n",
       " 'authors': 'Ziyu Li, Donghwan Shin',\n",
       " 'id': 35598,\n",
       " 'publication_date': None,\n",
       " 'publication_name': None,\n",
       " 'publication_url': None,\n",
       " 'title': 'Mutation-based Consistency Testing for Evaluating the Code Understanding   Capability of LLMs'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "class Keywords(BaseModel):\n",
    "    \"\"\"Keywords for a paper\"\"\"\n",
    "    keywords: str = Field(..., title=\"Keywords\", description=\"Keywords for a paper\")\n",
    "convert_pydantic_to_openai_function(Keywords)\n",
    "extraction_functions = [convert_pydantic_to_openai_function(Keywords)]\n",
    "extraction_model = model.bind(functions = extraction_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"keywords\": \"large language models, code understanding, code generation, benchmark, code mutations, inconsistency detection, LLM testing\"\\n}', 'name': 'Keywords'}})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "extraction_model.invoke(json.dumps(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'papers': [{'keywords': 'Large Language Models, code understanding, code generation, code mutations, inconsistencies, LLM testing, programming languages'},\n",
       "  {'keywords': 'LLMs, code generation, sub-functions, code completion, zero-shot evaluation, code editing instructions'},\n",
       "  {'keywords': 'code intelligence, deep learning, code representation learning, benchmark, neural models, code intelligence models'},\n",
       "  {'keywords': 'code representation learning, abstract syntax tree, code-related tasks, AST-based code representation'},\n",
       "  {'keywords': 'LLMs, code-specific adversarial attacks, code structure, transferability, programming languages'},\n",
       "  {'keywords': 'LLMs, code editing instructions, benchmark, open and closed models, code edits, fine-tuning'},\n",
       "  {'keywords': 'LLMs, code vulnerability repair, reinforcement learning, semantic reward, code comments'},\n",
       "  {'keywords': 'pre-trained models, source code, probing tasks, surface characteristics, syntactic characteristics, structural characteristics, semantic characteristics'},\n",
       "  {'keywords': 'LLMs, feedback-driven solution synthesis, security vulnerabilities, code refinement, PythonSecurityEval dataset'},\n",
       "  {'keywords': 'backdoor attacks, neural code models, triggers, task-agnostic attacks, code understanding, code generation'}]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Extract the keywords from the paper. Extract as detailed as possible and exclude irrelevant keywords. Do not make up or guess ANY extra information.\"),\n",
    "    (\"human\",\"{input}\"),\n",
    "])\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Keywords]\n",
    "paper_extraction_function = [convert_pydantic_to_openai_function(Info)]\n",
    "paper_extraction_model = model.bind(functions = paper_extraction_function, function_call={\"name\":\"Info\"})\n",
    "paper_extraction_chain = prompt | paper_extraction_model | JsonOutputFunctionsParser()\n",
    "\n",
    "paper_extraction_chain.invoke({\"input\": \" \".join(json.dumps(paper) for paper in results[0:10])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_helper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
